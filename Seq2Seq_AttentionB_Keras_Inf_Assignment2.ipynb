{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_AttentionB_Keras_Inf_Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbPrHdJlxT8T"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "os.chdir(\"drive/My Drive/IIITH/Advanced_NLP//Assignment_2\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ei7BqZ4xZ2I"
      },
      "source": [
        "eng_hi_Corpus = open(\"joint_Corpus.txt\",\"r\", encoding='utf-8')\n",
        "eng_hi_Corpus = eng_hi_Corpus.read().splitlines()\n",
        "df = pd.DataFrame(eng_hi_Corpus)\n",
        "X_train, X_test = train_test_split(df[0:10000], test_size=0.1, random_state=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBjWDlNoxd9p"
      },
      "source": [
        "eng_hi_train = np.array(X_train)\n",
        "eng_hi_test = np.array(X_test)\n",
        "\n",
        "### create train file for English and Hindi by splitting the text by \"!\"\n",
        "eng_Corpus_train = open(\"eng_Corpus_train.txt\",\"w\", encoding='utf-8')\n",
        "hin_Corpus_train = open(\"hin_Corpus_train.txt\",\"w\", encoding='utf-8')\n",
        "\n",
        "for i in range(eng_hi_train.shape[0]):\n",
        "    eng_Corpus_train.write(eng_hi_train[i][0].split('|')[0] + '\\n')\n",
        "    hin_Corpus_train.write(eng_hi_train[i][0].split('|')[1] + '\\n')\n",
        "  \n",
        "eng_Corpus_train.close()\n",
        "hin_Corpus_train.close() \n",
        "\n",
        "### create test file for English and Hindi by splitting the text by \"!\"\n",
        "\n",
        "eng_Corpus_test = open(\"eng_Corpus_test.txt\",\"w\", encoding='utf-8')\n",
        "hin_Corpus_test = open(\"hin_Corpus_test.txt\",\"w\", encoding='utf-8')\n",
        "\n",
        "for i in range(eng_hi_test.shape[0]):\n",
        "    eng_Corpus_test.write(eng_hi_test[i][0].split('|')[0] + '\\n')\n",
        "    hin_Corpus_test.write(eng_hi_test[i][0].split('|')[1] + '\\n')\n",
        "  \n",
        "eng_Corpus_test.close()\n",
        "hin_Corpus_test.close() "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuBdMqMfxgwN"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.models import load_model,save_model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Activation, dot, concatenate, Bidirectional, Attention\n",
        "from tensorflow.keras import activations\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
        "from keras.backend import expand_dims,sum\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import nltk"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPqJt_yhxjP6"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LSTM_NODES =128\n",
        "NUM_SENTENCES = 9000\n",
        "MAX_NUM_WORDS = 10000\n",
        "EMBEDDING_SIZE = 100"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyL2Spd7xlpT",
        "outputId": "fc5f0a4f-e838-440b-cebc-832b67dbdeb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "\n",
        "En_Corpus = open('eng_Corpus_train.txt','r',encoding = 'utf-8')\n",
        "cnt = 0 \n",
        "for line in En_Corpus.readlines():\n",
        "    #print(line)\n",
        "    if cnt < NUM_SENTENCES:\n",
        "      input_sentences.append(line.strip('\\n'))\n",
        "    cnt = cnt+1\n",
        "En_Corpus.close()\n",
        "\n",
        "Hi_Corpus = open('hin_Corpus_train.txt','r',encoding = 'utf-8')\n",
        "cnt = 0 \n",
        "for line in Hi_Corpus.readlines():\n",
        "  if cnt < NUM_SENTENCES:\n",
        "    output_sentences.append(line.strip('\\n') + ' <EOS>')\n",
        "    output_sentences_inputs.append('<SOS> '+line.strip('\\n') )\n",
        "  cnt = cnt +1\n",
        "Hi_Corpus.close()\n",
        "\n",
        "print(\"num samples input:\", len(input_sentences))\n",
        "print(\"num samples output:\", len(output_sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples input: 9000\n",
            "num samples output: 9000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNlkmY_txoQg",
        "outputId": "bbb7698d-67a9-4693-9e14-5815257700c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "input_tokenizer = Tokenizer(filters='')\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
        "num_words_input = len(word2idx_inputs) + 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique words in the input: 8219\n",
            "Length of longest sentence in input: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PA_Z3pwxqrD",
        "outputId": "1bb7f4ff-1a59-45a3-ec1f-4ad0d90040c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "output_tokenizer = Tokenizer(filters='')\n",
        "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique words in the output: 8270\n",
            "Length of longest sentence in the output: 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sHGzGOkxtSR"
      },
      "source": [
        "input_text = input_sentences\n",
        "target_text_input = output_sentences_inputs\n",
        "target_text_output = output_sentences\n",
        "\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_text)\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "         \n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(target_text_input)\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "          \n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(target_text_output)\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "          \n",
        "decoder_targets_one_hot = np.zeros((len(input_sentences),max_out_len,num_words_output),dtype='float32')\n",
        "\n",
        "#print('decoder_targets_one_hot ',decoder_targets_one_hot.shape)\n",
        "\n",
        "\n",
        "for i, d in enumerate(decoder_output_sequences):\n",
        "  for t, word in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, word] = 1\n",
        "          "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j4_XUn-xx_j",
        "outputId": "4fe0c224-6f4b-4487-9a31-17ecd8a90438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = load_model('Seq2Seq_attentionB_assignment2_v1.h5')\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 5, 128)       1052160     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 29)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 5, 256), (No 263168      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 29, 128)      1058688     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 29, 256), (N 394240      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims (TensorF (None, 1, 256)       0           lstm_1[0][1]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1, 10)        2570        tf_op_layer_ExpandDims[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5, 10)        2570        bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2 (TensorFlowOp (None, 5, 10)        0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Tanh (TensorFlowOpL (None, 5, 10)        0           tf_op_layer_AddV2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5, 1)         11          tf_op_layer_Tanh[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Max (TensorFlowOpLa (None, 1, 1)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowOpLa (None, 5, 1)         0           dense_2[0][0]                    \n",
            "                                                                 tf_op_layer_Max[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp (TensorFlowOpLa (None, 5, 1)         0           tf_op_layer_Sub[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa (None, 1, 1)         0           tf_op_layer_Exp[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorFlow (None, 5, 1)         0           tf_op_layer_Exp[0][0]            \n",
            "                                                                 tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul (TensorFlowOpLa (None, 5, 256)       0           tf_op_layer_RealDiv[0][0]        \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_1 (TensorFlowOp (None, 256)          0           tf_op_layer_Mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_1 (Tenso (None, 1, 256)       0           tf_op_layer_Sum_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_1 (TensorFlow (None, 29, 256)      0           tf_op_layer_ExpandDims_1[0][0]   \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 29, 8271)     2125647     tf_op_layer_AddV2_1[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 4,899,054\n",
            "Trainable params: 4,899,054\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jip9Iu7yx1Ad",
        "outputId": "e559e56a-d680-4795-900c-b833ae09c436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#For Inference Purpose\n",
        "encoder_inputs_placeholder = Input(shape=(max_input_len,))#model.get_layer('input_1')\n",
        "encoder_embedding = model.get_layer('embedding')\n",
        "encoder_bilstm = model.get_layer('bidirectional')\n",
        "\n",
        "x = encoder_embedding(encoder_inputs_placeholder)\n",
        "encoder_outputs,h_forward,c_forward, h_backward,c_backward = encoder_bilstm(x)\n",
        "print('encoder_outputs shape:',encoder_outputs.shape)\n",
        "\n",
        "h = concatenate([h_forward,h_backward],axis = 1)\n",
        "c = concatenate([c_forward,c_backward],axis = 1)\n",
        "\n",
        "encoder_states = [h, c]\n",
        "\n",
        "#Define Encoder Model\n",
        "encoder_model = Model(inputs = encoder_inputs_placeholder, outputs=[encoder_outputs, h, c])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_outputs shape: (None, 5, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1pAwqcax3vx",
        "outputId": "d1a14982-f8b9-4dfe-e0d8-5bb968deb518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "decoder_lstm = model.get_layer('lstm_1')\n",
        "decoder_state_input_h = Input(shape=(2*LSTM_NODES,),name='decoder_h_input')\n",
        "decoder_state_input_c = Input(shape=(2*LSTM_NODES,),name='decoder_c_input')\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "encoder_states_input = Input(shape=(max_input_len,LSTM_NODES*2), name = 'encoderstates_input')\n",
        "print('encoder_states_input shape',encoder_states_input.shape)\n",
        "encoder_outputs_inf = Input(shape=(max_input_len,LSTM_NODES*2))\n",
        "print('encoder_outputs_inf shape',encoder_outputs_inf.shape)\n",
        "\n",
        "print('decoder state input h shape:',decoder_state_input_h.shape)\n",
        "decoder_inputs_single = Input(shape=(1,),name='decoder_single_input')\n",
        "decoder_embedding = model.get_layer('embedding_1')\n",
        "\n",
        "print(' decoder_inputs_single shape:',decoder_inputs_single.shape)\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, decode_h, decode_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "decoder_states = [decode_h, decode_c ]\n",
        "print('decoder_outputs shape:',decoder_outputs.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_states_input shape (None, 5, 256)\n",
            "encoder_outputs_inf shape (None, 5, 256)\n",
            "decoder state input h shape: (None, 256)\n",
            " decoder_inputs_single shape: (None, 1)\n",
            "decoder_outputs shape: (None, 1, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPVtxhtzx6aK",
        "outputId": "dcb8dc97-10cc-4103-b72a-afdfc59263b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Luong's attention\n",
        "#attention = dot([decoder_outputs, encoder_states_input], axes=[2, 2])\n",
        "#attention = Activation('softmax')(attention)\n",
        "#context = dot([attention, encoder_states_input], axes=[2,1])\n",
        "#decoder_combined_context = concatenate([context, decoder_outputs])\n",
        "\n",
        "#Bhadnau's attention\n",
        "w1_b = model.get_layer('dense')\n",
        "w2_b = model.get_layer('dense_1')\n",
        "v_b  = model.get_layer('dense_2')\n",
        "\n",
        "encoder_h_timeaxis = expand_dims(encoder_states_input,1)\n",
        "score = v_b(activations.tanh(w1_b(encoder_h_timeaxis) + (w2_b(encoder_outputs_inf)) ))\n",
        "attention_softmax = activations.softmax(score,axis=1)\n",
        "context = attention_softmax * encoder_outputs_inf\n",
        "context_vector = sum(context,axis=1)\n",
        "context_vector_timeaxis = expand_dims(context_vector,1)\n",
        "decoder_combined_context = context_vector_timeaxis + decoder_outputs\n",
        "\n",
        "decoder_dense = model.get_layer('dense_3')\n",
        "decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs + [encoder_outputs_inf] + [encoder_states_input],\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n",
        "decoder_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoderstates_input (InputLayer [(None, 5, 256)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims (TensorF [(None, 1, 5, 256)]  0           encoderstates_input[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 5, 256)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   multiple             2570        tf_op_layer_ExpandDims[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5, 10)        2570        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2 (TensorFlowOp [(None, None, 5, 10) 0           dense[1][0]                      \n",
            "                                                                 dense_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Tanh (TensorFlowOpL [(None, None, 5, 10) 0           tf_op_layer_AddV2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 multiple             11          tf_op_layer_Tanh[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Max (TensorFlowOpLa [(None, 1, 5, 1)]    0           dense_2[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowOpLa [(None, None, 5, 1)] 0           dense_2[1][0]                    \n",
            "                                                                 tf_op_layer_Max[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp (TensorFlowOpLa [(None, None, 5, 1)] 0           tf_op_layer_Sub[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa [(None, 1, 5, 1)]    0           tf_op_layer_Exp[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorFlow [(None, None, 5, 1)] 0           tf_op_layer_Exp[0][0]            \n",
            "                                                                 tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul (TensorFlowOpLa [(None, None, 5, 256 0           tf_op_layer_RealDiv[0][0]        \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_single_input (InputLaye [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_1 (TensorFlowOp [(None, 5, 256)]     0           tf_op_layer_Mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         multiple             1058688     decoder_single_input[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_h_input (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_c_input (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 5, 256)]  0           tf_op_layer_Sum_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   multiple             394240      embedding_1[1][0]                \n",
            "                                                                 decoder_h_input[0][0]            \n",
            "                                                                 decoder_c_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_1 (TensorFlow [(None, None, 5, 256 0           tf_op_layer_ExpandDims_1[0][0]   \n",
            "                                                                 lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 multiple             2125647     tf_op_layer_AddV2_1[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 3,583,726\n",
            "Trainable params: 3,583,726\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29kezHZFx9fx"
      },
      "source": [
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXZhAG7Px_19"
      },
      "source": [
        "def translate_sentence(input_seq):\n",
        "    encoder_outputs, h, c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    states_value = [h,c]\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value + [encoder_outputs] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKMhmPSOyCOB"
      },
      "source": [
        "# prediction on test data\n",
        "\n",
        "input_sentences_test = []\n",
        "output_sentences_test = []\n",
        "\n",
        "En_Corpus_test = open('eng_Corpus_test.txt','r',encoding = 'utf-8')\n",
        "cnt = 0 \n",
        "for line in En_Corpus_test.readlines():\n",
        "    #print(line)\n",
        "    if cnt < NUM_SENTENCES:\n",
        "      input_sentences_test.append(line.strip('\\n'))\n",
        "    cnt = cnt+1\n",
        "En_Corpus_test.close()\n",
        "\n",
        "Hi_Corpus_test = open('hin_Corpus_test.txt','r',encoding = 'utf-8')\n",
        "cnt = 0 \n",
        "for line in Hi_Corpus_test.readlines():\n",
        "  if cnt < NUM_SENTENCES:\n",
        "    output_sentences_test.append(line.strip('\\n') + ' <EOS>')\n",
        "  cnt = cnt +1\n",
        "Hi_Corpus_test.close()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yTkiFD_yEsX"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smooth = SmoothingFunction().method4\n",
        "def calculate_bleu(text1,text2):\n",
        "  hypothesis = text1.split()\n",
        "  reference = text2.split()\n",
        "\n",
        "  reference_list = [reference] # list of references for 1 sentence.\n",
        "  bleu_score = nltk.translate.bleu_score.sentence_bleu(reference_list, hypothesis,smoothing_function = smooth)\n",
        "  return bleu_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3aKfElNyHSS",
        "outputId": "ce60d4e8-012e-4cb1-d06d-745ebdff2f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test_pred_result = open('test_prediction','w',encoding = 'utf-8')\n",
        "test_sent_bleu = {}\n",
        "for s in range(len(input_sentences_test)):\n",
        "  input_integer_seq = input_tokenizer.texts_to_sequences([input_sentences_test[s]])\n",
        "  encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "  translation = translate_sentence(encoder_input_sequences)\n",
        "  sent_bleu = calculate_bleu(output_sentences_test[s].strip('<EOS>'),translation)\n",
        "  test_sent_bleu[s] = sent_bleu\n",
        "  text = str(s) + ' ' + input_sentences_test[s] + '|' + output_sentences_test[s].strip('<EOS>') + 'Predicted: ' + translation + ' Bleu Score: ' + str(sent_bleu)\n",
        "  test_pred_result.write(text + '\\n')\n",
        "test_pred_result.close()\n",
        "\n",
        "  \n",
        "test_cospus_score = np.sum(list(test_sent_bleu.values()))/len(input_sentences_test)\n",
        "print('Test Corpus Bleu Score:',test_cospus_score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 5, 256) for input Tensor(\"encoderstates_input:0\", shape=(None, 5, 256), dtype=float32), but it was called on an input with incompatible shape (None, 256).\n",
            "Test Corpus Bleu Score: 0.16452619015883835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1QdNMw9yMlA",
        "outputId": "a28d110f-c1a8-40d9-d693-2a06a7b5b7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "test_sent_bleu_sorted_index = sorted(test_sent_bleu, key=test_sent_bleu.get, reverse=True)\n",
        "\n",
        "test_best = []\n",
        "for i in test_sent_bleu_sorted_index[0:20]:\n",
        "  test_best.append(i)\n",
        "\n",
        "for s in test_best:\n",
        "  input_integer_seq = input_tokenizer.texts_to_sequences([input_sentences_test[s]])\n",
        "  encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "  translation = translate_sentence(encoder_input_sequences)\n",
        "  sent_bleu = calculate_bleu(output_sentences_test[s].strip('<EOS>'),translation)\n",
        "  test_sent_bleu[s] = sent_bleu\n",
        "  text = str(s) + ' ' + input_sentences_test[s] + '|' + output_sentences_test[s].strip('<EOS>') + 'Predicted: ' + translation + ' Bleu Score: ' + str(sent_bleu)\n",
        "  print(text)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28 - Who is he?|- वह कौन है? Predicted: - वह कौन है? Bleu Score: 1.0\n",
            "133 \"Sweetheart I swear on you.\"|\"जानेमन मैं तुम पर कसम खाता हूँ।\" Predicted: \"जानेमन मैं तुम पर कसम खाता हूँ।\" Bleu Score: 1.0\n",
            "134 \"Sweetheart I swear on you.\"|\"जानेमन मैं तुम पर कसम खाता हूँ।\" Predicted: \"जानेमन मैं तुम पर कसम खाता हूँ।\" Bleu Score: 1.0\n",
            "253 man speaking native language:|पुरुष अपनी मातृभाषा में बोल रहा है: Predicted: पुरुष अपनी मातृभाषा में बोल रहा है: Bleu Score: 1.0\n",
            "301 \"Sweetheart I swear on you.\"|\"जानेमन मैं तुम पर कसम खाता हूँ।\" Predicted: \"जानेमन मैं तुम पर कसम खाता हूँ।\" Bleu Score: 1.0\n",
            "326 What are you doing?|तुम क्या कर रहे हो? Predicted: तुम क्या कर रहे हो? Bleu Score: 1.0\n",
            "507 \"Sweetheart I swear on you.\"|\"जानेमन मैं तुम पर कसम खाता हूँ।\" Predicted: \"जानेमन मैं तुम पर कसम खाता हूँ।\" Bleu Score: 1.0\n",
            "561 What are you doing?|तुम क्या कर रहे हो? Predicted: तुम क्या कर रहे हो? Bleu Score: 1.0\n",
            "587 man speaking native language:|पुरुष अपनी मातृभाषा में बोल रहा है: Predicted: पुरुष अपनी मातृभाषा में बोल रहा है: Bleu Score: 1.0\n",
            "646 - What is it?|- यह क्या है? Predicted: - यह क्या है? Bleu Score: 1.0\n",
            "778 What are you doing?|तुम क्या कर रहे हो? Predicted: तुम क्या कर रहे हो? Bleu Score: 1.0\n",
            "868 I am not with you.|मैं तुम्हारे साथ नहीं हूँ. Predicted: मैं तुम्हारे साथ नहीं हूँ. Bleu Score: 1.0\n",
            "935 \"Sweetheart I swear on you.\"|\"जानेमन मैं तुम पर कसम खाता हूँ।\" Predicted: \"जानेमन मैं तुम पर कसम खाता हूँ।\" Bleu Score: 1.0\n",
            "596 [Moses speaking native language]|[मोज़ेस अपनी मातृभाषा में बोल रहा है] Predicted: अपनी मातृभाषा में बोल रहा है] Bleu Score: 0.8091067115702212\n",
            "733 He was not your father!|वह अपने पिता नहीं था! Predicted: वह अपने पिता नहीं था. Bleu Score: 0.668740304976422\n",
            "941 man #2 speaking native language:|पुरुष #2 मातृभाषा में बोल रहा है: Predicted: पुरुष अपनी मातृभाषा में बोल रहा है: Bleu Score: 0.6434588841607617\n",
            "926 That's what they said.|यही कारण है कि वे क्या कहा। Predicted: यही कारण है कि वे क्या कर सकते हैं. Bleu Score: 0.6080253214198359\n",
            "179 What's going on here?|यहाँ क्या हो रहा है? Predicted: यहाँ पर क्या हो रहा है? Bleu Score: 0.5789300674674098\n",
            "170 NdeR M@nkÖÖ ™ © P@rM!|©@ पीआर एम nderएम@ nkÖÖ  Predicted: ©@ पीआर एम nderएम@ nköö  Bleu Score: 0.537284965911771\n",
            "631 Do you want to die?|तुम मरने के लिए चाहते हैं? Predicted: आप के लिए चाहते हैं? Bleu Score: 0.5081327481546147\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}